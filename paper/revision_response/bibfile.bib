@article{hyperopt,
author = {Bergstra, J. and Yamins, D. and Cox, D. D.},
title = {Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures},
year = {2013},
publisher = {JMLR.org},
abstract = {Many computer vision algorithms depend on configuration settings that are typically hand-tuned in the course of evaluating the algorithm for a particular data set. While such parameter tuning is often presented as being incidental to the algorithm, correctly setting these parameter choices is frequently critical to realizing a method's full potential. Compounding matters, these parameters often must be re-tuned when the algorithm is applied to a new problem domain, and the tuning process itself often depends on personal experience and intuition in ways that are hard to quantify or describe. Since the performance of a given technique depends on both the fundamental quality of the algorithm and the details of its tuning, it is sometimes difficult to know whether a given technique is genuinely better, or simply better tuned.In this work, we propose a meta-modeling approach to support automated hyperparameter optimization, with the goal of providing practical tools that replace hand-tuning with a reproducible and unbiased optimization process. Our approach is to expose the underlying expression graph of how a performance metric (e.g. classification accuracy on validation examples) is computed from hyperparameters that govern not only how individual processing steps are applied, but even which processing steps are included. A hyperparameter optimization algorithm transforms this graph into a program for optimizing that performance metric. Our approach yields state of the art results on three disparate computer vision problems: a face-matching verification task (LFW), a face identification task (PubFig83) and an object recognition task (CIFAR-10), using a single broad class of feed-forward vision architectures.},
booktitle = {Proceedings of the 30th International Conference on International Conference on Machine Learning - Volume 28},
pages = {I–115–I–123},
location = {Atlanta, GA, USA},
series = {ICML'13}
}

@phdthesis{Schuch,
          school = {Universit{\"a}t Regensburg},
           title = {Implementation of quantum algorithms with Josephson charge qubits},
           month = {December},
            year = {2002},
          author = {Norbert Schuch},
             url = {https://epub.uni-regensburg.de/1511/}
}

@misc{ibmqx,
  author = {Alwin Zulehner, Stefan Hillmich, Alexandru Paler, and Robert Wille},
  title = {ibm\_qx\_mapping},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/iic-jku/ibm_qx_mapping}}
}


@software{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.2.5},
  year = {2018},
}

@misc{ Qiskit,
       author = {MD SAJID ANIS et al},
       title = {Qiskit: An Open-source Framework for Quantum Computing},
       year = {2021},
       doi = {10.5281/zenodo.2573505}
}

@article{candes2011robust,
  title={Robust principal component analysis?},
  author={Cand{\`e}s, Emmanuel J and Li, Xiaodong and Ma, Yi and Wright, John},
  journal={Journal of the ACM (JACM)},
  volume={58},
  number={3},
  pages={1--37},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@article{donoho2006most,
  title={For most large underdetermined systems of linear equations the minimal 1-norm solution is also the sparsest solution},
  author={Donoho, David L},
  journal={Communications on Pure and Applied Mathematics: A Journal Issued by the Courant Institute of Mathematical Sciences},
  volume={59},
  number={6},
  pages={797--829},
  year={2006},
  publisher={Wiley Online Library}
}

@article{candes2006robust,
  title={Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information},
  author={Cand{\`e}s, Emmanuel J and Romberg, Justin and Tao, Terence},
  journal={IEEE Transactions on information theory},
  volume={52},
  number={2},
  pages={489--509},
  year={2006},
  publisher={IEEE}
}

@article{tibshirani1996regression,
  title={Regression shrinkage and selection via the lasso},
  author={Tibshirani, Robert},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={58},
  number={1},
  pages={267--288},
  year={1996},
  publisher={Wiley Online Library}
}

@misc{CPFlow,
  author = {Nikita Nemkov, and Ilia Luchnikov, and Evgeniy Kiktenko, and Aleksey Fedorov},
  title = {cpflow},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/idnm/cpflow}}
}
